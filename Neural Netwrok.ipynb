{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e67b39f",
   "metadata": {},
   "source": [
    "## TensorFlow\n",
    "One of the main reasons for success of neural networks is the introduction of new software packages designed specifically for creating and training neural network models. These packages have the capability to train the model on specific hardware such as CPUs, GPUs or even TPUs.  \n",
    "\n",
    "In this notebook, we use TensorFlow to train a neural network model. The other main package for neural networks is Torch. Its python wrapper pyTorch.  \n",
    "First, we need to install the package on the machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "721c4b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.0-cp38-cp38-macosx_10_11_x86_64.whl (199.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 199.0 MB 35.6 MB/s eta 0:00:01   |██████████▎                     | 63.6 MB 7.2 MB/s eta 0:00:19     |█████████████████▊              | 110.2 MB 24.6 MB/s eta 0:00:04     |███████████████████████▊        | 147.6 MB 65.6 MB/s eta 0:00:01███████████████▊| 197.2 MB 35.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.41.1-cp38-cp38-macosx_10_10_x86_64.whl (3.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9 MB 60.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting keras~=2.6\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 50.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp38-cp38-macosx_10_9_x86_64.whl (15.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.6 MB 44.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 14.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/raha/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 42.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.0-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 73.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /Users/raha/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/raha/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/raha/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 51.9 MB/s eta 0:00:01     |███████████████▏                | 2.7 MB 51.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 72.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.3.2-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 52.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /Users/raha/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/raha/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/raha/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/raha/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/raha/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/raha/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/raha/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: clang, termcolor\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=212d85c13f98054e8904eb9a9030c517f1af42d6ee11ab8d978b2be4d5b41deb\n",
      "  Stored in directory: /Users/raha/Library/Caches/pip/wheels/f1/60/77/22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=fc19e243236bcba6e6a1687bb1d60c6f024dd0cdac6b2522ba2b82e628ab6c50\n",
      "  Stored in directory: /Users/raha/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built clang termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.1\n",
      "    Uninstalling numpy-1.20.1:\n",
      "      Successfully uninstalled numpy-1.20.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "Successfully installed absl-py-0.15.0 astunparse-1.6.3 cachetools-4.2.4 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-2.3.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.41.1 h5py-3.1.0 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.19.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-estimator-2.6.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fcdf21",
   "metadata": {},
   "source": [
    "## Binary Classification with Neural Networks\n",
    "In this notbook, we consider a simple problem in healthcare. Can we predict diabetes based on other healthcare information. For this problem we use **Pima Indians onset of diabetes** dataset from **UCI Machine Learning** repository. This is dataset of structured data.\n",
    "\n",
    "### Pima Indians Onset of Diabetes Dataset\n",
    "This dataset has 767 row. The dependent variable, Onset, has values 1 for onset of diabetes and 0 for no sign of the disease.\n",
    "\n",
    "#### Features\n",
    "This dataset has 8 input variable. All features are numeric and there is no missing values.\n",
    "\n",
    "1. Number of times pregnant\n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "3. Diastolic blood pressure (mm Hg)\n",
    "4. Triceps skin fold thickness (mm)\n",
    "5. 2-Hour serum insulin (mu U/ml)\n",
    "6. Body mass index (weight in kg/(height in m)^2)\n",
    "7. Diabetes pedigree function (history in relatives)\n",
    "8. Age (years)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2feb5f9",
   "metadata": {},
   "source": [
    "### Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ffe3a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Pregnancy          768 non-null    int64  \n",
      " 1   Glucose            768 non-null    int64  \n",
      " 2   Blood_Pressure     768 non-null    int64  \n",
      " 3   Skin_fold          768 non-null    int64  \n",
      " 4   Insulin            768 non-null    int64  \n",
      " 5   BMI                768 non-null    float64\n",
      " 6   Relatives_History  768 non-null    float64\n",
      " 7   Age                768 non-null    int64  \n",
      " 8   Onset              768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancy</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Blood_Pressure</th>\n",
       "      <th>Skin_fold</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Relatives_History</th>\n",
       "      <th>Age</th>\n",
       "      <th>Onset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancy  Glucose  Blood_Pressure  Skin_fold  Insulin   BMI  \\\n",
       "0          6      148              72         35        0  33.6   \n",
       "1          1       85              66         29        0  26.6   \n",
       "2          8      183              64          0        0  23.3   \n",
       "3          1       89              66         23       94  28.1   \n",
       "4          0      137              40         35      168  43.1   \n",
       "\n",
       "   Relatives_History  Age  Onset  \n",
       "0              0.627   50      1  \n",
       "1              0.351   31      0  \n",
       "2              0.672   32      1  \n",
       "3              0.167   21      0  \n",
       "4              2.288   33      1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('pima-indians-diabetes.data.csv',header=None)\n",
    "col_list = ['Pregnancy','Glucose','Blood_Pressure','Skin_fold','Insulin','BMI','Relatives_History','Age','Onset']\n",
    "df.columns = col_list\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79485f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we seperate input and output data.\n",
    "df_y = pd.DataFrame(df['Onset'])\n",
    "df_x = df[['Pregnancy','Glucose','Blood_Pressure','Skin_fold','Insulin','BMI','Relatives_History','Age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9e2cbb",
   "metadata": {},
   "source": [
    "### Unbalanced Dataset\n",
    "There are 500 of 0 labels and 268 of 1 labels, i.e., we have roughly 2 times 0s compared to 1s in this data. This is a problem when we want to choose a threshold to separate 1s from 0s given their probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a8916d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 500, 1: 268})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(df_y['Onset']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "808eca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep some data for out of sample testing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_x,df_y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b989af",
   "metadata": {},
   "source": [
    "### Neural Network Model\n",
    "\n",
    "Let's start with a feedforward network with 2 hidden layers. TensorFlow has the ability of define each layer as a function. To create the model, we simply compose these functions. The input layer is defined with function Input. Then we have two hidden layers defined by Dense function. The first of these layers has 12 nodes and the next one has 8. \n",
    "\n",
    "The Model functions gets the input and output layers as creates a Keras (an internal tensorflow package) model for us. Our model needs a loss function and an optimizer (a version of gradient decent). Here we go with Binary Crossentropy and Adam. The training evaluation metric is accuracy.\n",
    "\n",
    "The summary function lists the layers of the created model, number of their nodes and number of parameter in each layer. \n",
    "\n",
    "This is one of the simplest models that can be defined. It is just a two layer perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9655ac37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "\n",
    "input1 = Input(shape=(8,))\n",
    "logits1 = Dense(units=12, activation=\"relu\")(input1)\n",
    "logits2 = Dense(units=8, activation=\"relu\")(logits1)\n",
    "#logits2 = Dropout(0.5)(logits1)\n",
    "logits3 = Dense(units=1, activation=\"sigmoid\")(logits2)\n",
    "\n",
    "model = Model(inputs=input1, outputs=logits3)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d55e461",
   "metadata": {},
   "source": [
    "### Learning Rate\n",
    "The optimizer function has the default learning rate value. We get this value by running following command.\n",
    "\n",
    "One can change this value or even define a callback function to change it based on a schedule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d65976ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "print(round(model.optimizer.lr.numpy(), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56edc71c",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Number of epochs and batch size are two of the most important hyper parameters of each neural network model. Epochs determine how many times the model should be retained on the data and batch size determine during each epoch how many of the data points should be considered at each iteration of the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7cb4c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "56/56 [==============================] - 1s 4ms/step - loss: 10.4028 - accuracy: 0.4257 - val_loss: 4.4304 - val_accuracy: 0.5484\n",
      "Epoch 2/20\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 4.1238 - accuracy: 0.4547 - val_loss: 2.2781 - val_accuracy: 0.4516\n",
      "Epoch 3/20\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 2.2276 - accuracy: 0.4928 - val_loss: 1.4087 - val_accuracy: 0.6452\n",
      "Epoch 4/20\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 1.2624 - accuracy: 0.5761 - val_loss: 1.1358 - val_accuracy: 0.5968\n",
      "Epoch 5/20\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 1.0105 - accuracy: 0.6087 - val_loss: 1.0192 - val_accuracy: 0.6935\n",
      "Epoch 6/20\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.9164 - accuracy: 0.6214 - val_loss: 1.0119 - val_accuracy: 0.6452\n",
      "Epoch 7/20\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.8824 - accuracy: 0.6304 - val_loss: 1.1676 - val_accuracy: 0.6774\n",
      "Epoch 8/20\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.8489 - accuracy: 0.6304 - val_loss: 0.9596 - val_accuracy: 0.6129\n",
      "Epoch 9/20\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.7952 - accuracy: 0.6630 - val_loss: 0.9929 - val_accuracy: 0.5968\n",
      "Epoch 10/20\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.7775 - accuracy: 0.6649 - val_loss: 0.9561 - val_accuracy: 0.6613\n",
      "Epoch 11/20\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.7786 - accuracy: 0.6649 - val_loss: 0.9573 - val_accuracy: 0.6613\n",
      "Epoch 12/20\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.7367 - accuracy: 0.6721 - val_loss: 0.9058 - val_accuracy: 0.6774\n",
      "Epoch 13/20\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 0.6522 - val_loss: 0.8837 - val_accuracy: 0.6452\n",
      "Epoch 14/20\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.7303 - accuracy: 0.6649 - val_loss: 0.8652 - val_accuracy: 0.6452\n",
      "Epoch 15/20\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.6703 - val_loss: 0.7836 - val_accuracy: 0.6452\n",
      "Epoch 16/20\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.6630 - val_loss: 0.9004 - val_accuracy: 0.6613\n",
      "Epoch 17/20\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.6705 - accuracy: 0.6721 - val_loss: 0.7885 - val_accuracy: 0.6452\n",
      "Epoch 18/20\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6695 - accuracy: 0.7029 - val_loss: 0.8665 - val_accuracy: 0.6613\n",
      "Epoch 19/20\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6374 - accuracy: 0.7029 - val_loss: 0.7393 - val_accuracy: 0.6613\n",
      "Epoch 20/20\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6423 - accuracy: 0.6866 - val_loss: 0.7058 - val_accuracy: 0.6613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f97f920c160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train,\n",
    "            validation_split=0.1,\n",
    "            batch_size=10,\n",
    "            shuffle=True,\n",
    "            epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6246ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc85d208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7689 - accuracy: 0.6818\n",
      "Accuracy: 68.18\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test,y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94461a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 69.06\n",
      "Accuracy: 68.18\n",
      "Confusion Matrix:\n",
      "[[75 24]\n",
      " [25 30]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "\n",
    "y_train_pred = (model.predict(X_train) > 0.5).astype(int)\n",
    "train_acc = accuracy_score(y_train,y_train_pred)\n",
    "print('Train Accuracy:',round(train_acc * 100,2))\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print('Accuracy:',round(acc*100,2))\n",
    "print('Confusion Matrix:')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11afa7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Pregnancy          768 non-null    float64\n",
      " 1   Glucose            768 non-null    float64\n",
      " 2   Blood_Pressure     768 non-null    float64\n",
      " 3   Skin_fold          768 non-null    float64\n",
      " 4   Insulin            768 non-null    float64\n",
      " 5   BMI                768 non-null    float64\n",
      " 6   Relatives_History  768 non-null    float64\n",
      " 7   Age                768 non-null    float64\n",
      " 8   Onset              768 non-null    int64  \n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 54.1 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancy</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Blood_Pressure</th>\n",
       "      <th>Skin_fold</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Relatives_History</th>\n",
       "      <th>Age</th>\n",
       "      <th>Onset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500745</td>\n",
       "      <td>0.234415</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.427136</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396423</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.919598</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347243</td>\n",
       "      <td>0.253629</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.447236</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.418778</td>\n",
       "      <td>0.038002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.642325</td>\n",
       "      <td>0.943638</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancy   Glucose  Blood_Pressure  Skin_fold   Insulin       BMI  \\\n",
       "0   0.352941  0.743719        0.590164   0.353535  0.000000  0.500745   \n",
       "1   0.058824  0.427136        0.540984   0.292929  0.000000  0.396423   \n",
       "2   0.470588  0.919598        0.524590   0.000000  0.000000  0.347243   \n",
       "3   0.058824  0.447236        0.540984   0.232323  0.111111  0.418778   \n",
       "4   0.000000  0.688442        0.327869   0.353535  0.198582  0.642325   \n",
       "\n",
       "   Relatives_History       Age  Onset  \n",
       "0           0.234415  0.483333      1  \n",
       "1           0.116567  0.166667      0  \n",
       "2           0.253629  0.183333      1  \n",
       "3           0.038002  0.000000      0  \n",
       "4           0.943638  0.200000      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[col_list[:-1]] = scaler.fit_transform(df[col_list[:-1]])\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94ffd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we seperate input and output data.\n",
    "df_y = pd.DataFrame(df['Onset'])\n",
    "df_x = df[['Pregnancy','Glucose','Blood_Pressure','Skin_fold','Insulin','BMI','Relatives_History','Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fbadca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 500, 1: 268})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(df_y['Onset']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4fdf1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep some data for out of sample testing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_x,df_y, test_size=0.2,random_state=42)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3b4fe9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2d05e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 721\n",
      "Trainable params: 721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense,Dropout,Input\n",
    "\n",
    "logits1 = Input(shape=(8,))\n",
    "logits2 = Dense(units=16, activation=\"relu\")(logits1)\n",
    "logits3 = Dense(units=32, activation=\"relu\")(logits2)\n",
    "#logits4 = Dense(units=32, activation=\"relu\")(logits3)\n",
    "#logits4 = Dropout(0.1)(logits3)\n",
    "logits20 = Dense(units=1, activation=\"relu\")(logits3)\n",
    "\n",
    "model = Model(inputs=logits1, outputs=logits20)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e6be592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 1s 725ms/step - loss: 0.5993 - accuracy: 0.6993 - val_loss: 0.5885 - val_accuracy: 0.6935\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5959 - accuracy: 0.7029 - val_loss: 0.5856 - val_accuracy: 0.6935\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5926 - accuracy: 0.7029 - val_loss: 0.5828 - val_accuracy: 0.6935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f97decdd5b0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train,\n",
    "            validation_split=0.1,\n",
    "            batch_size=617,\n",
    "            shuffle=True,\n",
    "            epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0b40e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7403\n",
      "Accuracy: 74.03\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test,y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2584f5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 65.31\n",
      "Accuracy: 64.29\n",
      "Confusion Matrix:\n",
      "[[99  0]\n",
      " [55  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "\n",
    "y_train_pred = (model.predict(X_train) > 0.5).astype(int)\n",
    "train_acc = accuracy_score(y_train,y_train_pred)\n",
    "print('Train Accuracy:',round(train_acc * 100,2))\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print('Accuracy:',round(acc*100,2))\n",
    "print('Confusion Matrix:')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e1489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
